{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc65a90f-147e-4c5f-9815-d22ce91166ab",
   "metadata": {},
   "source": [
    "1. nltk\n",
    "2. razdel (natasha)\n",
    "3. DeepPavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2478284a-5469-4126-b762-60f838deb4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cf171a-9c72-4e68-88f4-1ea16e2fcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "raw = '''Тетрадки к занятиям выкладываются в папках с датами в названиях. Чтобы скачать репозиторий с нуля, используйте команду git clone <path>. Чтобы обновить содержимое репозитория на локальном компьютере, используйте команду git pull, когда находитесь в локальной папке репозитория.\n",
    "\n",
    "Каждое занятие будет содержать следующие тетрадки:\n",
    "\n",
    "sem%d - задачки, которые мы решаем на семинарах\n",
    "lec%d - конспект лекционной части\n",
    "hw%d (опционально, но в основном всегда) - домашние задания. Домашки можно присылать мне по почте в .ipynb или .py. (Или кидать ссылки на колаб)'''\n",
    "\n",
    "sents = sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f03a6c0-0e6e-4546-8f4d-bffc16563849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки к занятиям выкладываются в папках с датами в названиях.',\n",
       " 'Чтобы скачать репозиторий с нуля, используйте команду git clone <path>.',\n",
       " 'Чтобы обновить содержимое репозитория на локальном компьютере, используйте команду git pull, когда находитесь в локальной папке репозитория.',\n",
       " 'Каждое занятие будет содержать следующие тетрадки:\\n\\nsem%d - задачки, которые мы решаем на семинарах\\nlec%d - конспект лекционной части\\nhw%d (опционально, но в основном всегда) - домашние задания.',\n",
       " 'Домашки можно присылать мне по почте в .ipynb или .py.',\n",
       " '(Или кидать ссылки на колаб)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540824c3-f1bb-4225-af2b-06dc73f4f613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки к занятиям выкладываются в папках с датами в названиях.',\n",
       " 'Чтобы скачать репозиторий с нуля, используйте команду git clone <path>.',\n",
       " 'Чтобы обновить содержимое репозитория на локальном компьютере, используйте команду git pull, когда находитесь в локальной папке репозитория.',\n",
       " 'Каждое занятие будет содержать следующие тетрадки:\\n\\nsem%d - задачки, которые мы решаем на семинарах\\nlec%d - конспект лекционной части\\nhw%d (опционально, но в основном всегда) - домашние задания.',\n",
       " 'Домашки можно присылать мне по почте в .ipynb или .py.',\n",
       " '(Или кидать ссылки на колаб)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "\n",
    "sents = [s.text for s in sentenize(raw)]\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831be2fd-e4a6-43aa-95f3-a797cb27e023",
   "metadata": {},
   "source": [
    "# nltk:\n",
    "\n",
    "pip install nltk\n",
    "\n",
    "import nltk \\\n",
    "nltk.donwload()\n",
    "\n",
    "# razdel:\n",
    "\n",
    "pip install razdel\n",
    "\n",
    "# deeppavlov:\n",
    "\n",
    "pip install rusenttokenize\n",
    "\n",
    "# spacy:\n",
    "\n",
    "pip install spacy\n",
    "\n",
    "python -m spacy download ru_core_news_sm (md, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3881779-09ae-4527-86f7-8f7b451a62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки к занятиям выкладываются в папках с датами в названиях.',\n",
       " 'Чтобы скачать репозиторий с нуля, используйте команду git clone <path>.',\n",
       " 'Чтобы обновить содержимое репозитория на локальном компьютере, используйте команду git pull, когда находитесь в локальной папке репозитория.',\n",
       " 'Каждое занятие будет содержать следующие тетрадки:\\n\\nsem%d - задачки, которые мы решаем на семинарах\\nlec%d - конспект лекционной части\\nhw%d (опционально, но в основном всегда) - домашние задания.',\n",
       " 'Домашки можно присылать мне по почте в .ipynb или .py.',\n",
       " '(Или кидать ссылки на колаб)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n",
    "\n",
    "sents = ru_sent_tokenize(raw)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f9599f-9629-4b67-9c14-1dad83359e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки', 'к', 'занятиям', 'выкладываются', 'в']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e509f94-5b47-4c36-95b5-481b61315582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки', 'к', 'занятиям', 'выкладываются', 'в']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = [t.text for t in tokenize(raw)]\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22b958-7019-4ba0-9605-e428858b3e72",
   "metadata": {},
   "source": [
    "pip install spacy\n",
    "\n",
    "python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be4102f-8bc4-4904-b7a3-fc42c3536c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "doc = nlp(raw)\n",
    "tokens = [t.text for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2395fa-ad2c-4503-a73c-5c0869c92a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки', 'к', 'занятиям', 'выкладываются', 'в']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58154bb-f88b-4878-81cb-55ef93350689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "бегущ\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "print(stemmer.stem('бегущий'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726806e6-8012-4b5a-a69f-425cfbd3120a",
   "metadata": {},
   "source": [
    "pymorphy2\n",
    "\n",
    "pip install pymorphy2\n",
    "pip install -U pymorphy2-dicts-ru - обновить словарь "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29bc47a-cd76-4460-8474-6190a4893872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тетрадка\n",
      "к\n",
      "занятие\n",
      "выкладываться\n",
      "в\n",
      "папка\n",
      "с\n",
      "дата\n",
      "в\n",
      "название\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "for token in tokens[:10]:\n",
    "    parse = morph.parse(token)\n",
    "    print(parse[0].normal_form)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18b027ce-af5a-4210-9866-7ea383ef713c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b31f4-5842-460e-ad53-1846f650d644",
   "metadata": {},
   "source": [
    "mystem\n",
    "\n",
    "pip install git+https://github.com/nlpub/pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf2a41b8-7446-415e-acd3-58b90fafaab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to C:\\Users\\Aswin/.local/bin\\mystem.exe from http://download.cdn.yandex.net/mystem/mystem-3.1-win-64bit.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['тетрадка', 'к', 'занятие', 'выкладываться', 'в']\n"
     ]
    }
   ],
   "source": [
    "import pymystem3\n",
    "\n",
    "m = pymystem3.Mystem(entire_input=False)\n",
    "\n",
    "lemmas = m.lemmatize(raw)\n",
    "print(lemmas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491ce012-2b02-4163-bf7c-70e009cf20ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'тетрадка', 'gr': 'S,жен,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'Тетрадки'},\n",
       " {'analysis': [{'lex': 'к', 'gr': 'PR='}], 'text': 'к'},\n",
       " {'analysis': [{'lex': 'занятие', 'gr': 'S,сред,неод=дат,мн'}],\n",
       "  'text': 'занятиям'},\n",
       " {'analysis': [{'lex': 'выкладываться',\n",
       "    'gr': 'V,нп=непрош,мн,изъяв,3-л,несов'}],\n",
       "  'text': 'выкладываются'},\n",
       " {'analysis': [{'lex': 'в', 'gr': 'PR='}], 'text': 'в'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = m.analyze(raw)\n",
    "analysis[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9792aa1c-d59f-418f-9702-50d19a186f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S,жен,неод=(вин,мн|род,ед|им,мн)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[0]['analysis'][0]['gr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3988d3-0a82-4002-b314-06a2336c2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '...'\n",
    "\n",
    "alanyze = m.analyze(file_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fec06632-f5e8-4c65-8150-43ea12dc4f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_pos(analysis[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e9407-0e4a-4527-9f11-cec81a74c52e",
   "metadata": {},
   "source": [
    "pip install rnnmorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b8d888-c6bb-4b3b-9d5d-498704234046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "\n",
    "predictor = RNNMorphPredictor(language='ru')\n",
    "parse = predictor.predict(tokens) # [parse0, parse1, parse2, ...] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211cf254-06cb-468e-88e1-cd6be8699d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<normal_form=тетрадка; word=Тетрадки; pos=NOUN; tag=Case=Nom|Gender=Fem|Number=Plur; score=0.9944>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47571ef0-2c35-4f04-88b4-d00e5c10547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'тетрадка'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1a5ab0-a149-4f61-87c2-6a411bfbe708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Тетрадки', 'к', 'занятиям', 'выкладываются', 'в']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465a3db0-fc7d-485e-a481-ed3665f39793",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = '''Нахско-дагестанские языки (также восточнокавказские) — языковая семья, распространённая в восточной части Северного Кавказа (в Дагестане, Чечне и Ингушетии), отчасти в Азербайджане и Грузии, а также в диаспорах разных стран. По разным оценкам, число говорящих на языках семьи варьируется от 2,6 до 4,3 миллионов человек. На некоторых из них говорит не более нескольких сотен человек.\n",
    "\n",
    "Нахско-дагестанские языки разделились из общего праязыка к концу III тысячелетия до нашей эры. За своё существование они подверглись значительному влиянию иранских и тюркских языков, а также арабского и, с XX века, русского. Существует несколько гипотез, объединяющих нахско-дагестанские семьи в макросемьи, в том числе с другими языками Кавказа, но ни одна из них не является общепризнанной. Вследствие географических и культурных особенностей региона дагестанские языки существовали в относительной изоляции друг от друга, что привело к значительному языковому разнообразию. Большинство нахско-дагестанских языков бесписьменные.\n",
    "\n",
    "Генеалогическая классификация внутри семьи и разделение на языки и диалекты являются предметом научных дискуссий. Традиционно семья делится на шесть ветвей. Нахско-дагестанские языки выделяются сравнительно богатым набором согласных и широким распространением фарингализации. В грамматике отличительными чертами семьи являются эргативно-абсолютивное кодирование аргументов глагола, две системы падежей (обычных и локативных) и наличие категории именного класса.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429319c8-00b2-487f-ac32-871bb5b76c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f033c9-502f-40a8-8e92-26ae429813a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [s.text for s in sentenize(raw)]\n",
    "for i in range(len(sents)):\n",
    "    sents[i] = [t.text for t in tokenize(sents[i])]\n",
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e2e329-20b3-46e8-b27f-c2ba52e3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myfile.conllu', 'w', encoding='utf8') as file:\n",
    "    for sent in sents:\n",
    "        for i, token in enumerate(sent):  # for i in range(len(sent))\n",
    "            print(f'{i + 1}\\t{token}', file=file)\n",
    "        print(file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b8d17-b720-412c-ae30-29ae9f941dc4",
   "metadata": {},
   "source": [
    "pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf88596-9340-4a61-be85-fc4d8c54dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyconll\n",
    "\n",
    "t = pyconll.load_from_file('myfilem.conllu')\n",
    "for sentence in t:\n",
    "    for token in sentence:\n",
    "        ...\n",
    "        \n",
    "token.id\n",
    "token.form\n",
    "token.lemma\n",
    "token.upos\n",
    "token.feats\n",
    "token.head\n",
    "token.deprel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
