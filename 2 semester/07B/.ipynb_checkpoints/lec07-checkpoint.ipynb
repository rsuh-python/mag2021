{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7178a0-fb4f-40d9-be09-df6015fcc600",
   "metadata": {},
   "source": [
    "### Крупные библиотеки NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7d890-a4f0-4d36-adc3-b0532ee48dde",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "\n",
    "NLTK - одна из самых первых библиотек такого рода; она огромная и содержит очень много разных инструментов, некоторые из них никак не связаны между собой (в отличие от spacy). NLTK - больше исследовательская библиотека, конструктор своего рода. Для NLTK есть учебник, написанный авторами: [NLTK book](https://www.nltk.org/book/). Для этого учебника специально существует подмодуль book, который обычно импортируется целиком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96c22e-068d-45eb-ae78-2746998d842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7937f-917f-4439-9a75-c7c8828d4061",
   "metadata": {},
   "source": [
    "В этом модуле есть некий набор текстов и набор предложений, с которыми можно поиграться. \n",
    "\n",
    "Центральный объект для NLTK (по крайней мере, при работе с корпусами) - это Text (nltk.text.Text). По сути, в этом объекте содержится сам текст в виде списка токенов, но у него есть дополнительные методы. Что можно делать с объектом класса Text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471bd330-5d17-40f1-83a1-2001d7771f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 84 matches:\n",
      "[ Moby Dick by Herman Melville 1851 ] ETYMOLOGY . ( Su\n",
      "hat white whale must be the same that some call Moby Dick .\" \" Moby Dick ?\" shouted Ahab . \" Do ye k\n",
      " must be the same that some call Moby Dick .\" \" Moby Dick ?\" shouted Ahab . \" Do ye know the white w\n",
      "ib in a squall . Death and devils ! men , it is Moby Dick ye have seen -- Moby Dick -- Moby Dick !\" \n",
      " devils ! men , it is Moby Dick ye have seen -- Moby Dick -- Moby Dick !\" \" Captain Ahab ,\" said Sta\n"
     ]
    }
   ],
   "source": [
    "text1.concordance('Moby', width=100, lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730854c2-9119-436a-b04c-a910b6931ac4",
   "metadata": {},
   "source": [
    "Конкорданс ищет первые n вхождений заданного слова с шириной контекста width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80ff0b7-d80b-444e-8506-c44d50b81207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship boat sea time captain world man deck pequod other whales air\n",
      "water head crew line thing side way body\n"
     ]
    }
   ],
   "source": [
    "text1.similar('whale', num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c85270-4ff4-4093-81d0-bdff00d9d63f",
   "metadata": {},
   "source": [
    "similar возвращает num слов, которые встречаются в похожих контекстах (дистрибутивная похожесть). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56663ecc-52c6-40ba-96ed-ea0592d6fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_s the_and the_is the_in the_the the_as the_was the_which the_i\n",
      "a_in the_has the_when the_had the_with the_to the_by the_so the_that\n",
      "the_would the_a\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts(['whale', 'ship'])  # тоже можно задать параметр num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cdd87-cffc-48e6-8521-07f61a2af62a",
   "metadata": {},
   "source": [
    "common_contexts ищет те самые совпадающие контексты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfd941d-5e90-4c26-aff5-9ab49a56f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text1.dispersion_plot(['Ahab', 'Ishmael'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c58dd-365f-448e-8449-36d57e0d08ee",
   "metadata": {},
   "source": [
    "Можно построить график распределения слов по тексту (без NumPy и matplotlib график не работает, поэтому установите эти две библиотеки, если еще не). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab84e04-67ea-4ec6-85f3-114c856af397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('Moby')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98d0a7-496e-4276-a120-5ca7e73e07e6",
   "metadata": {},
   "source": [
    "Можно посчитать количество вхождений какого-то слова. Кстати, к текстам можно применять обычные функции len(), set() и подобные. И срезы с индексами работают!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3729eb54-7107-4e21-8a80-a2d6864f9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long , from one to the top - mast , and no coffin and went out a sea\n",
      "captain -- this peaking of the whales . , so as to preserve all his\n",
      "might had in former years abounding with them , they toil with their\n",
      "lances , strange tales of Southern whaling . at once the bravest\n",
      "Indians he was , after in vain strove to pierce the profundity . ?\n",
      "then ?\" a levelled flame of pale , And give no chance , watch him ;\n",
      "though the line , it is to be gainsaid . have been\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'long , from one to the top - mast , and no coffin and went out a sea\\ncaptain -- this peaking of the whales . , so as to preserve all his\\nmight had in former years abounding with them , they toil with their\\nlances , strange tales of Southern whaling . at once the bravest\\nIndians he was , after in vain strove to pierce the profundity . ?\\nthen ?\" a levelled flame of pale , And give no chance , watch him ;\\nthough the line , it is to be gainsaid . have been'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.generate(length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ede59-2349-426e-a568-7a4f32c68de3",
   "metadata": {},
   "source": [
    "Можно сгенерировать текст, \"похожий\" на оригинальный. Это делается с помощью n-грамов (или n-грамм, я видела разные варианты по-русски...): nltk просто в случайном порядке совмещает эти n-грамы. Как можно видеть, не слишком полезный метод, однако можно побаловаться. \n",
    "\n",
    "Важнее то, что в nltk есть утилиты для работы с n-грамами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17db2aaf-376a-445d-a58c-07f1f55ed379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'suburb', 'of'),\n",
       " ('suburb', 'of', 'Saffron'),\n",
       " ('of', 'Saffron', 'Park'),\n",
       " ('Saffron', 'Park', 'lay'),\n",
       " ('Park', 'lay', 'on'),\n",
       " ('lay', 'on', 'the'),\n",
       " ('on', 'the', 'sunset'),\n",
       " ('the', 'sunset', 'side'),\n",
       " ('sunset', 'side', 'of'),\n",
       " ('side', 'of', 'London'),\n",
       " ('of', 'London', ','),\n",
       " ('London', ',', 'as'),\n",
       " (',', 'as', 'red'),\n",
       " ('as', 'red', 'and'),\n",
       " ('red', 'and', 'ragged'),\n",
       " ('and', 'ragged', 'as'),\n",
       " ('ragged', 'as', 'a'),\n",
       " ('as', 'a', 'cloud'),\n",
       " ('a', 'cloud', 'of'),\n",
       " ('cloud', 'of', 'sunset'),\n",
       " ('of', 'sunset', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams # bigrams\n",
    "\n",
    "list(ngrams(sent9, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6aaf4-a636-457a-8488-fc1f368e87d6",
   "metadata": {},
   "source": [
    "Функция ngrams (или bigrams) возвращает список всех н-грамов списка токенов, который ей дать. N-грамы еще принимают число n. \n",
    "\n",
    "У класса Text есть метод, который возвращает коллокации (частотные н-грамы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997835cd-8823-4b11-af45-bf873936583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda69c8c-3903-47b5-b289-76a554c4b8b7",
   "metadata": {},
   "source": [
    "Также я, кажется, забыла вам рассказать про частотный словарь, но там ничего супер-сложного нет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d577e3-5795-42f0-b74f-a603c7adc31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Herman',\n",
       " 'Melville',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'School',\n",
       " 'threadbare',\n",
       " 'lexicons',\n",
       " 'mockingly']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.hapaxes()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78a6ea-ff81-49e5-93a9-d0f2bd2f621e",
   "metadata": {},
   "source": [
    "По существу, это обычный каунтер, у которого есть парочка плюшек. Из интересных - hapaxes (список всех слов, которые встретились в тексте только один раз)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcef76-cd87-4a02-ad64-3cc80ddfb82f",
   "metadata": {},
   "source": [
    "Как создать собственный объект класса Text? Достаточно токенизировать свой текст (любым токенизатором) и передать его в класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c36a9-be8f-4cc9-a453-d09d8e4d13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d54549-6ed4-47ea-9e09-55f129af444b",
   "metadata": {},
   "source": [
    "Из интересного в nltk есть еще небольшой набор своих морфопарсеров (в основном безбожно устаревших). В nltk используется тагсет PennTreebank (там есть, кстати, и размеченные корпуса). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95c3371-02ed-4af3-be50-50c68b79be10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT'),\n",
       " ('suburb', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Saffron', 'NNP'),\n",
       " ('Park', 'NNP'),\n",
       " ('lay', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sunset', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('London', 'NNP'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('red', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('ragged', 'VBD'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('cloud', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('sunset', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sent9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fe57a-6ad6-458a-8f03-cb25497f35b3",
   "metadata": {},
   "source": [
    "Значение любого тега можно узнать у самого nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5ac852-2496-46e9-8e03-7d438ae991d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0a21e-a566-434c-a874-45aef9055c82",
   "metadata": {},
   "source": [
    "pos_tag = lookup tagger (то есть, он смотрит в словаре). В nltk также реализованы самые простые статистические тэггеры (то есть, такие, которые приписывают часть речи в соответствии с вероятностью). Unigram tagger приписывает часть речи в соответствии с тем, как часто эта часть речи приписывалась слову в его обучающем датасете; bigram tagger смотрит еще на предыдущее слово. Работают они из рук вон плохо, потому что это базовые реализации идеи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972f3a4a-e945-4ba8-8216-643b57803577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', None),\n",
       " ('suburb', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Saffron', None),\n",
       " ('Park', 'NN-TL'),\n",
       " ('lay', 'JJ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('sunset', None),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('London', 'NP'),\n",
       " (',', ','),\n",
       " ('as', 'CS'),\n",
       " ('red', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('ragged', None),\n",
       " ('as', 'CS'),\n",
       " ('a', 'AT'),\n",
       " ('cloud', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('sunset', None),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown \n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents) # сразу обучаем его\n",
    "unigram_tagger.tag(sent9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f53575-5953-46fd-a7cd-b09a95facd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Call', None), ('me', None), ('Ishmael', None), ('.', None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_sents)\n",
    "bigram_tagger.tag(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426f54d-0f36-499b-952f-f29936add5b8",
   "metadata": {},
   "source": [
    "В общем, с морфологией там все не очень интересно. Гораздо интереснее в этом отношении spacy и его обертки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72480cdb-3138-4f93-8b4f-9eb77703a399",
   "metadata": {},
   "source": [
    "#### SpaCy\n",
    "\n",
    "Спейси - более современная библиотека, которая написана в Cython и использует нейронные сети. Интерфейс спейси довольно удобный и однообразный. Центральное понятие для спейси - это pipeline: то есть, набор действий, которые спейси совершает с текстом. Чтобы обработать текст на любом из языков, представленных в библиотеке ([список](https://spacy.io/usage/models)), достаточно завести пустой пайплайн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8540a0a4-caa7-420a-a633-fec9e7592b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 22:27:28.933294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-15 22:27:28.933346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "doc = nlp('My beautiful sentence is here.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7a77b-55cd-4cf1-97af-a8185db701e0",
   "metadata": {},
   "source": [
    "Предупреждения выдает библиотека tensorflow, которая сообщает, что у вас не настроена CUDA, но их можно игнорировать, как и предлагается. \n",
    "\n",
    "Пустой пайплайн превращает наш текст в особый объект, в котором текст разделен на токены, и можно у этих токенов смотреть самые простые характеристики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41348ecf-9364-49b2-ac8e-adf51550bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№ 0. Токен:              My. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 1. Токен:       beautiful. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 2. Токен:        sentence. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 3. Токен:              is. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 4. Токен:            here. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 5. Токен:               .. Является словом: False. Является пунктуацией: True. Похож на число: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'№ {token.i}. Токен: {token.text:>15}. Является словом: {token.is_alpha}. Является пунктуацией: {token.is_punct}. Похож на число: {token.like_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508816ad-2288-4fd6-8cdd-61ac53b0b0ea",
   "metadata": {},
   "source": [
    "Объект doc также позволяет смотреть спаны (несколько токенов, срез текста):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a920c46-8965-416f-aaec-a0bebee45dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beautiful sentence'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[1:3]\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b695ab-603f-4381-887d-5fcd077ac94b",
   "metadata": {},
   "source": [
    "Ну, это все прекрасно, но хотелось бы чего-то большего. Для spacy есть довольно много предобученных моделей для разных языков (список см. выше). Модельки нужно устанавливать (скачивать) с помощью команды в командной строке - она написана у них на сайте (python -m spacy download имя_модели). Когда вы загрузили модельку, вы можете ее использовать в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0c4fb29-14ec-4f1d-91a0-0656956f11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb2381-9d38-4d58-9b42-ed96172b0c22",
   "metadata": {},
   "source": [
    "Теперь уже можно получить сведения поинтереснее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea249b7-78f0-4263-b82c-fe75cc587bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "278c4b30-2162-4506-884a-042ef60d666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. The             POS: DET    SyntR: det       Head: Army\n",
      " 1. 4th             POS: ADJ    SyntR: amod      Head: Army\n",
      " 2. Army            POS: PROPN  SyntR: nsubj     Head: was\n",
      " 3. was             POS: AUX    SyntR: ROOT      Head: was\n",
      " 4. a               POS: DET    SyntR: det       Head: formation\n",
      " 5. Royal           POS: PROPN  SyntR: compound  Head: Army\n",
      " 6. Yugoslav        POS: ADJ    SyntR: amod      Head: Army\n",
      " 7. Army            POS: PROPN  SyntR: compound  Head: formation\n",
      " 8. formation       POS: NOUN   SyntR: attr      Head: was\n",
      " 9. mobilised       POS: VERB   SyntR: acl       Head: formation\n",
      "10. prior           POS: ADV    SyntR: advmod    Head: mobilised\n",
      "11. to              POS: ADP    SyntR: prep      Head: prior\n",
      "12. the             POS: DET    SyntR: det       Head: invasion\n",
      "13. German          POS: PROPN  SyntR: npadvmod  Head: led\n",
      "14. -               POS: PUNCT  SyntR: punct     Head: led\n",
      "15. led             POS: VERB   SyntR: amod      Head: invasion\n",
      "16. invasion        POS: NOUN   SyntR: pobj      Head: to\n",
      "17. of              POS: ADP    SyntR: prep      Head: invasion\n",
      "18. the             POS: DET    SyntR: det       Head: Kingdom\n",
      "19. Kingdom         POS: PROPN  SyntR: pobj      Head: of\n",
      "20. of              POS: ADP    SyntR: prep      Head: Kingdom\n",
      "21. Yugoslavia      POS: PROPN  SyntR: pobj      Head: of\n",
      "22. during          POS: ADP    SyntR: prep      Head: invasion\n",
      "23. World           POS: PROPN  SyntR: compound  Head: II\n",
      "24. War             POS: PROPN  SyntR: compound  Head: II\n",
      "25. II              POS: PROPN  SyntR: pobj      Head: during\n",
      "26. .               POS: PUNCT  SyntR: punct     Head: was\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.i:2}. {token.text:15} POS: {token.pos_:6} SyntR: {token.dep_:9} Head: {token.head.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fd223-344d-4366-a3ab-73158dc0cadd",
   "metadata": {},
   "source": [
    "Также spacy позволяет разметить именованные сущности и посмотреть, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49e5348a-441c-4624-858b-df1ea4baa720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: The 4th Army                   Label: ORG\n",
      "Entity: Royal Yugoslav Army            Label: ORG\n",
      "Entity: German                         Label: NORP\n",
      "Entity: the Kingdom of Yugoslavia      Label: GPE\n",
      "Entity: World War II                   Label: EVENT\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'Entity: {ent.text:30} Label: {ent.label_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23279eae-5672-4e4e-a89e-154cf42b6393",
   "metadata": {},
   "source": [
    "Если аббревиатуры вас смущают, spacy легко предоставит расшифровки (для всех!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93a88d2f-40ab-4392-9d22-986c7742f666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NORP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35bc844b-59e0-4238-9a8c-e23310fa8baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'object of preposition'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('pobj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759c3b8-8efb-400c-92f4-3f96cb1cfc1f",
   "metadata": {},
   "source": [
    "Итак, а теперь самое интересное - это обертки для spacy + udpipe. UD, как известно - очень известный и влиятельный проект (чешский), цель которого - унифицировать тагсет для всех языков мира, причем как в морфологии, так и в синтаксисе. Неудивительно, что, поскольку в UD существует большое количество размеченных датасетов (русским языком активно занималась О. Ляшевская), то они обучили и свой парсер. Сам парсер написан в плюсах и не очень дружелюбен, но обертки для spacy делают жизнь проще. \n",
    "\n",
    "Внимание: я обычно это забываю, но прежде чем установить udpipe, **нужно поставить C++ Build Tools** (с сайта майкрософт, это бесплатно). Это нужно, чтобы скомпилировать udpipe из исходников в сях. Адрес сайта, откуда брать их, сам pip обычно подсказывает, но в целом можно просто погуглить. \n",
    "\n",
    "Две оболочки для udpipe, которые мы посмотрели - это spacy_udpipe и corpy. Обе нужно устанавливать:\n",
    "\n",
    "    pip install spacy_udpipe\n",
    "    pip install corpy\n",
    "    \n",
    "Для spacy_udpipe вообще ничего больше не нужно, там максимально автоматизированно скачиваются модельки. Для corpy приходится скачивать искомую модель руками, [отсюда](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-3131). Эту модель вы можете положить куда угодно, главное потом указать corpy путь к ней. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76c2b1a8-e395-4689-a934-bc3c935c395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'en' language\n"
     ]
    }
   ],
   "source": [
    "import spacy_udpipe\n",
    "\n",
    "spacy_udpipe.download('en')  # эту команду достаточно выполнить только один раз - она как nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c06bda-bb5f-4754-bfd7-e8fd3bfb13aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. The             Lemma: the             POS: DET    SyntR: det       Head: Army\n",
      " 1. 4th             Lemma: 4th             POS: ADJ    SyntR: amod      Head: Army\n",
      " 2. Army            Lemma: Army            POS: PROPN  SyntR: nsubj     Head: formation\n",
      " 3. was             Lemma: be              POS: AUX    SyntR: cop       Head: formation\n",
      " 4. a               Lemma: a               POS: DET    SyntR: det       Head: formation\n",
      " 5. Royal           Lemma: Royal           POS: PROPN  SyntR: compound  Head: Army\n",
      " 6. Yugoslav        Lemma: Yugoslav        POS: PROPN  SyntR: compound  Head: Army\n",
      " 7. Army            Lemma: Army            POS: PROPN  SyntR: compound  Head: formation\n",
      " 8. formation       Lemma: formation       POS: NOUN   SyntR: nsubj     Head: mobilised\n",
      " 9. mobilised       Lemma: mobilise        POS: VERB   SyntR: ROOT      Head: mobilised\n",
      "10. prior           Lemma: prior           POS: ADJ    SyntR: case      Head: invasion\n",
      "11. to              Lemma: to              POS: ADP    SyntR: fixed     Head: prior\n",
      "12. the             Lemma: the             POS: DET    SyntR: det       Head: invasion\n",
      "13. German          Lemma: german          POS: ADJ    SyntR: obl:npmod Head: led\n",
      "14. -               Lemma: -               POS: PUNCT  SyntR: punct     Head: led\n",
      "15. led             Lemma: lead            POS: VERB   SyntR: amod      Head: invasion\n",
      "16. invasion        Lemma: invasion        POS: NOUN   SyntR: obl       Head: mobilised\n",
      "17. of              Lemma: of              POS: ADP    SyntR: case      Head: Kingdom\n",
      "18. the             Lemma: the             POS: DET    SyntR: det       Head: Kingdom\n",
      "19. Kingdom         Lemma: Kingdom         POS: PROPN  SyntR: nmod      Head: invasion\n",
      "20. of              Lemma: of              POS: ADP    SyntR: case      Head: Yugoslavia\n",
      "21. Yugoslavia      Lemma: Yugoslavia      POS: PROPN  SyntR: nmod      Head: Kingdom\n",
      "22. during          Lemma: during          POS: ADP    SyntR: case      Head: II\n",
      "23. World           Lemma: World           POS: PROPN  SyntR: compound  Head: War\n",
      "24. War             Lemma: War             POS: PROPN  SyntR: compound  Head: II\n",
      "25. II              Lemma: ii              POS: PROPN  SyntR: nmod      Head: Kingdom\n",
      "26. .               Lemma: .               POS: PUNCT  SyntR: punct     Head: mobilised\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy_udpipe.load('en')\n",
    "doc = nlp('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')\n",
    "for token in doc:\n",
    "    print(f'{token.i:2}. {token.text:15} Lemma: {token.lemma_:15} POS: {token.pos_:6} SyntR: {token.dep_:9} Head: {token.head.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1fe03-ccc6-4987-8d4c-5e76d7bd0baa",
   "metadata": {},
   "source": [
    "Это все прекрасно, но способ извлечь грамматические характеристики я нашла только в corpy. Это делается так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8efbc0e6-ca40-4cd5-a329-3614dec48446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpy.udpipe import Model\n",
    "\n",
    "model = Model('english-partut-ud-2.5-191206.udpipe')  \n",
    "# тут и нужно указать путь к вашей модели. Если она лежит в той же папке, что и скрипт, достаточно только имени файла\n",
    "\n",
    "sents = model.process('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9ae8d-adeb-41cd-bacb-8657949e1360",
   "metadata": {},
   "source": [
    "corpy возвращает генератор (то есть, итерируемый объект, который как магазин автомата, расстреляли все патроны - он опустел; повторно по генератору итерироваться нельзя). Генератор на каждом шаге выдает предложение (объект специального класса Sentence()), а в предложении - объекты класса Word(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d145b44-91b6-4321-ae7d-d5d9c17da575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<root>          Лемма: <root>          POS: <root> Грам. инфа: <root>\n",
      "The             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "4th             Лемма: 4th             POS: ADJ Грам. инфа: Degree=Pos\n",
      "Army            Лемма: army            POS: NOUN Грам. инфа: Number=Sing\n",
      "was             Лемма: be              POS: AUX Грам. инфа: Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "a               Лемма: a               POS: DET Грам. инфа: Definite=Ind|Number=Sing|PronType=Art\n",
      "Royal           Лемма: royal           POS: PROPN Грам. инфа: \n",
      "Yugoslav        Лемма: Yugoslav        POS: PROPN Грам. инфа: \n",
      "Army            Лемма: army            POS: PROPN Грам. инфа: \n",
      "formation       Лемма: formation       POS: NOUN Грам. инфа: Number=Sing\n",
      "mobilised       Лемма: mobilize        POS: VERB Грам. инфа: Mood=Ind|Person=3|Tense=Past|VerbForm=Fin\n",
      "prior           Лемма: prior           POS: ADJ Грам. инфа: Degree=Pos\n",
      "to              Лемма: to              POS: ADP Грам. инфа: \n",
      "the             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "German          Лемма: German          POS: PROPN Грам. инфа: \n",
      "-               Лемма: -               POS: PUNCT Грам. инфа: \n",
      "led             Лемма: lead            POS: VERB Грам. инфа: Tense=Past|VerbForm=Part\n",
      "invasion        Лемма: invasion        POS: NOUN Грам. инфа: Number=Sing\n",
      "of              Лемма: of              POS: ADP Грам. инфа: \n",
      "the             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "Kingdom         Лемма: kingdom         POS: NOUN Грам. инфа: Number=Sing\n",
      "of              Лемма: of              POS: ADP Грам. инфа: \n",
      "Yugoslavia      Лемма: Yugoslavia      POS: PROPN Грам. инфа: \n",
      "during          Лемма: during          POS: ADP Грам. инфа: \n",
      "World           Лемма: world           POS: NOUN Грам. инфа: Number=Sing\n",
      "War             Лемма: war             POS: NOUN Грам. инфа: Number=Sing\n",
      "II              Лемма: second          POS: ADJ Грам. инфа: Degree=Pos|NumType=Ord\n",
      ".               Лемма: .               POS: PUNCT Грам. инфа: \n",
      "Алилуя!\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    for word in sent.words:\n",
    "        print(f'{word.form:15} Лемма: {word.lemma:15} POS: {word.upostag} Грам. инфа: {word.feats}')\n",
    "print('Алилуя!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f22f20-3340-484c-8d2a-250974d98761",
   "metadata": {},
   "source": [
    "у corpy, кстати, есть свой способ вывода имеющейся информации (хотя, по-моему, в юпитере и так красиво выводится...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2a9a480-fda5-4f92-8a7c-b4a61eae1193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\n",
      "   comments=[\n",
      "     '# newdoc',\n",
      "     '# newpar',\n",
      "     '# sent_id = 1',\n",
      "     '# text = The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.'],\n",
      "   words=[\n",
      "     Word(id=0, <root>),\n",
      "     Word(id=1,\n",
      "          form='The',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=3,\n",
      "          deprel='det'),\n",
      "     Word(id=2,\n",
      "          form='4th',\n",
      "          lemma='4th',\n",
      "          xpostag='A',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos',\n",
      "          head=3,\n",
      "          deprel='amod'),\n",
      "     Word(id=3,\n",
      "          form='Army',\n",
      "          lemma='army',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=9,\n",
      "          deprel='nsubj'),\n",
      "     Word(id=4,\n",
      "          form='was',\n",
      "          lemma='be',\n",
      "          xpostag='V',\n",
      "          upostag='AUX',\n",
      "          feats='Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
      "          head=9,\n",
      "          deprel='cop'),\n",
      "     Word(id=5,\n",
      "          form='a',\n",
      "          lemma='a',\n",
      "          xpostag='RI',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Ind|Number=Sing|PronType=Art',\n",
      "          head=9,\n",
      "          deprel='det'),\n",
      "     Word(id=6,\n",
      "          form='Royal',\n",
      "          lemma='royal',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=9,\n",
      "          deprel='nmod'),\n",
      "     Word(id=7,\n",
      "          form='Yugoslav',\n",
      "          lemma='Yugoslav',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=6,\n",
      "          deprel='flat'),\n",
      "     Word(id=8,\n",
      "          form='Army',\n",
      "          lemma='army',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=6,\n",
      "          deprel='flat'),\n",
      "     Word(id=9,\n",
      "          form='formation',\n",
      "          lemma='formation',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='nsubj'),\n",
      "     Word(id=10,\n",
      "          form='mobilised',\n",
      "          lemma='mobilize',\n",
      "          xpostag='V',\n",
      "          upostag='VERB',\n",
      "          feats='Mood=Ind|Person=3|Tense=Past|VerbForm=Fin',\n",
      "          head=0,\n",
      "          deprel='root'),\n",
      "     Word(id=11,\n",
      "          form='prior',\n",
      "          lemma='prior',\n",
      "          xpostag='A',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos',\n",
      "          head=10,\n",
      "          deprel='amod'),\n",
      "     Word(id=12,\n",
      "          form='to',\n",
      "          lemma='to',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=17,\n",
      "          deprel='case'),\n",
      "     Word(id=13,\n",
      "          form='the',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=17,\n",
      "          deprel='det'),\n",
      "     Word(id=14,\n",
      "          form='German',\n",
      "          lemma='German',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=16,\n",
      "          deprel='obl',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=15,\n",
      "          form='-',\n",
      "          lemma='-',\n",
      "          xpostag='FF',\n",
      "          upostag='PUNCT',\n",
      "          head=16,\n",
      "          deprel='punct',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=16,\n",
      "          form='led',\n",
      "          lemma='lead',\n",
      "          xpostag='V',\n",
      "          upostag='VERB',\n",
      "          feats='Tense=Past|VerbForm=Part',\n",
      "          head=17,\n",
      "          deprel='acl'),\n",
      "     Word(id=17,\n",
      "          form='invasion',\n",
      "          lemma='invasion',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='obl'),\n",
      "     Word(id=18,\n",
      "          form='of',\n",
      "          lemma='of',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=20,\n",
      "          deprel='case'),\n",
      "     Word(id=19,\n",
      "          form='the',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=20,\n",
      "          deprel='det'),\n",
      "     Word(id=20,\n",
      "          form='Kingdom',\n",
      "          lemma='kingdom',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=17,\n",
      "          deprel='nmod'),\n",
      "     Word(id=21,\n",
      "          form='of',\n",
      "          lemma='of',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=22,\n",
      "          deprel='case'),\n",
      "     Word(id=22,\n",
      "          form='Yugoslavia',\n",
      "          lemma='Yugoslavia',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=20,\n",
      "          deprel='nmod'),\n",
      "     Word(id=23,\n",
      "          form='during',\n",
      "          lemma='during',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=25,\n",
      "          deprel='case'),\n",
      "     Word(id=24,\n",
      "          form='World',\n",
      "          lemma='world',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=25,\n",
      "          deprel='nmod'),\n",
      "     Word(id=25,\n",
      "          form='War',\n",
      "          lemma='war',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='obl'),\n",
      "     Word(id=26,\n",
      "          form='II',\n",
      "          lemma='second',\n",
      "          xpostag='NO',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos|NumType=Ord',\n",
      "          head=25,\n",
      "          deprel='amod',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=27,\n",
      "          form='.',\n",
      "          lemma='.',\n",
      "          xpostag='FS',\n",
      "          upostag='PUNCT',\n",
      "          head=10,\n",
      "          deprel='punct',\n",
      "          misc='SpaceAfter=No')])]\n"
     ]
    }
   ],
   "source": [
    "from corpy.udpipe import pprint\n",
    "\n",
    "pprint(list(model.process('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
